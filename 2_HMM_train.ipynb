{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSAvAQeUboQH"
   },
   "source": [
    "# Entrenando un Modelo Markoviano Latente (HMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apZTvqywabkM"
   },
   "source": [
    "## Corpus de español: \n",
    "\n",
    "* AnCora | Github: https://github.com/UniversalDependencies/UD_Spanish-AnCora\n",
    "\n",
    "* usamos el conllu parser para leer el corpus: https://pypi.org/project/conllu/\n",
    "\n",
    "* Etiquetas Universal POS (Documentación): https://universaldependencies.org/u/pos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "7SyjRpNdXx6l",
    "outputId": "c199c05e-2c3a-47fa-ee61-b562798bc369",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: conllu in ./venv/lib/python3.7/site-packages (4.2.2)\n",
      "Clonando en 'UD_Spanish-AnCora'...\n",
      "remote: Enumerating objects: 31, done.\u001B[K\n",
      "remote: Counting objects: 100% (31/31), done.\u001B[K\n",
      "remote: Compressing objects: 100% (22/22), done.\u001B[K\n",
      "remote: Total 526 (delta 14), reused 25 (delta 9), pack-reused 495\u001B[K\n",
      "Recibiendo objetos: 100% (526/526), 115.95 MiB | 581.00 KiB/s, listo.\n",
      "Resolviendo deltas: 100% (361/361), listo.\n"
     ]
    }
   ],
   "source": [
    "#@title dependencias previas\n",
    "!pip install conllu\n",
    "!git clone https://github.com/UniversalDependencies/UD_Spanish-AnCora.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KxqUFhyXozz",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#@title leyendo el corpus AnCora\n",
    "from conllu import parse_incr \n",
    "wordList = []\n",
    "data_file = open(\"UD_Spanish-AnCora/es_ancora-ud-dev.conllu\", \"r\", encoding=\"utf-8\")\n",
    "for tokenlist in parse_incr(data_file):\n",
    "    print(tokenlist.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "atcsH_bm9L6T",
    "outputId": "d9a117a8-2ea4-45ad-eada-cb5d8266b3d0",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Estructura de los tokens etiquetados del corpus\n",
    "tokenlist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Ia8ZEUJmaQdw",
    "outputId": "a002ba40-875b-4f2a-99f1-4984a5c9e9b3",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tokenlist[1]['form']+'|'+tokenlist[1]['upos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2F4mvQqN5Tm"
   },
   "source": [
    "## Entrenamiento del modelo - Calculo de conteos:\n",
    "\n",
    "* tags (tags) `tagCountDict`: $C(tag)$\n",
    "* emisiones (word|tag) `emissionProbDict`: $C(word|tag)$\n",
    "* transiciones (tag|prevtag) `transitionDict`: $C(tag|prevtag)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N04oYlQgeAW9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tagCountDict = {} \n",
    "emissionDict = {}\n",
    "transitionDict = {}\n",
    "\n",
    "tagtype = 'upos'\n",
    "data_file = open(\"UD_Spanish-AnCora/es_ancora-ud-dev.conllu\", \"r\", encoding=\"utf-8\")\n",
    "\n",
    "# Calculando conteos (pre-probabilidades)\n",
    "for tokenlist in parse_incr(data_file):\n",
    "  prevtag = None\n",
    "  for token in tokenlist:\n",
    "\n",
    "    # C(tag)\n",
    "    tag = token[tagtype]\n",
    "    if tag in tagCountDict.keys():\n",
    "      tagCountDict[tag] += 1\n",
    "    else:\n",
    "      tagCountDict[tag] = 1\n",
    "\n",
    "    # C(word|tag) -> probabilidades emision\n",
    "    wordtag = token['form'].lower()+'|'+token[tagtype] # (word|tag)\n",
    "    if wordtag in emissionDict.keys():\n",
    "      emissionDict[wordtag] = emissionDict[wordtag] + 1\n",
    "    else:\n",
    "      emissionDict[wordtag] = 1\n",
    "\n",
    "    #  C(tag|tag_previo) -> probabilidades transición\n",
    "    if prevtag is None:\n",
    "      prevtag = tag\n",
    "      continue\n",
    "    transitiontags = tag+'|'+prevtag\n",
    "    if transitiontags in transitionDict.keys():\n",
    "      transitionDict[transitiontags] = transitionDict[transitiontags] + 1\n",
    "    else:\n",
    "      transitionDict[transitiontags] = 1\n",
    "    prevtag = tag\n",
    "    \n",
    "#transitionDict\n",
    "#emissionDict\n",
    "#tagCountDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIXcZxSdOO__"
   },
   "source": [
    "## Entrenamiento del modelo - calculo de probabilidades\n",
    "* probabilidades de transición:\n",
    "$$P(tag|prevtag) = \\frac{C(prevtag, tag)}{C(prevtag)}$$\n",
    "\n",
    "* probabilidades de emisión:\n",
    " $$P(word|tag) = \\frac{C(word|tag)}{C(tag)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "KznFFp2COzf7",
    "outputId": "878214a9-e32a-41ce-87b6-e615b33c7ada",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "transitionProbDict = {} # matriz A\n",
    "emissionProbDict = {} # matriz B\n",
    "\n",
    "# transition Probabilities \n",
    "for key in transitionDict.keys():\n",
    "  tag, prevtag = key.split('|')\n",
    "  if tagCountDict[prevtag]>0:\n",
    "    transitionProbDict[key] = transitionDict[key]/(tagCountDict[prevtag])\n",
    "  else:\n",
    "    print(key)\n",
    "\n",
    "# emission Probabilities \n",
    "for key in emissionDict.keys():\n",
    "  word, tag = key.split('|')\n",
    "  if emissionDict[key]>0:\n",
    "    emissionProbDict[key] = emissionDict[key]/tagCountDict[tag]\n",
    "  else:\n",
    "    print(key)\n",
    "\n",
    "transitionProbDict['ADJ|ADJ']\n",
    "#emissionProbDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AyYqw1FZZ89"
   },
   "source": [
    "## Guardar parámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Ido5QcAkY4OK",
    "outputId": "41e7d6c2-68c4-4090-826a-951ab980b238",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('transitionHMM.npy', transitionProbDict)\n",
    "np.save('emissionHMM.npy', emissionProbDict)\n",
    "transitionProbdict = np.load('transitionHMM.npy', allow_pickle='TRUE').item()\n",
    "transitionProbDict['ADJ|ADJ']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "apZTvqywabkM"
   ],
   "name": "[Lectura_7/8]HMM_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}